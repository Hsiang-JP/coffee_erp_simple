import {
  IDBContext,
  WebLocksExclusive
} from "./chunk-6EDQOGJI.js";
import {
  Base
} from "./chunk-2SIIJYGA.js";
import {
  SQLITE_CANTOPEN,
  SQLITE_IOCAP_BATCH_ATOMIC,
  SQLITE_IOCAP_SAFE_APPEND,
  SQLITE_IOCAP_SEQUENTIAL,
  SQLITE_IOCAP_UNDELETABLE_WHEN_OPEN,
  SQLITE_IOERR,
  SQLITE_IOERR_SHORT_READ,
  SQLITE_LOCK_SHARED,
  SQLITE_NOTFOUND,
  SQLITE_OK,
  SQLITE_OPEN_CREATE,
  SQLITE_OPEN_DELETEONCLOSE,
  SQLITE_OPEN_READONLY
} from "./chunk-ASNZVNAU.js";
import {
  __privateAdd,
  __privateGet,
  __privateMethod,
  __privateSet
} from "./chunk-DWA4UIM3.js";

// node_modules/wa-sqlite/src/examples/IDBBatchAtomicVFS.js
var SECTOR_SIZE = 512;
var MAX_TASK_MILLIS = 3e3;
var DEFAULT_OPTIONS = {
  durability: "default",
  purge: "deferred",
  purgeAtLeast: 16
};
function log(...args) {
}
var _options, _mapIdToFile, _idb, _pendingPurges, _taskTimestamp, _pendingAsync, _IDBBatchAtomicVFS_instances, xWriteHelper_fn, xSyncHelper_fn, maybePurge_fn, bound_fn, reblockIfNeeded_fn;
var IDBBatchAtomicVFS = class extends Base {
  constructor(idbDatabaseName = "wa-sqlite", options = DEFAULT_OPTIONS) {
    super();
    __privateAdd(this, _IDBBatchAtomicVFS_instances);
    __privateAdd(this, _options);
    /** @type {Map<number, OpenedFileEntry>} */
    __privateAdd(this, _mapIdToFile, /* @__PURE__ */ new Map());
    /** @type {IDBContext} */
    __privateAdd(this, _idb);
    /** @type {Set<string>} */
    __privateAdd(this, _pendingPurges, /* @__PURE__ */ new Set());
    __privateAdd(this, _taskTimestamp, performance.now());
    __privateAdd(this, _pendingAsync, /* @__PURE__ */ new Set());
    this.name = idbDatabaseName;
    __privateSet(this, _options, Object.assign({}, DEFAULT_OPTIONS, options));
    __privateSet(this, _idb, new IDBContext(openDatabase(idbDatabaseName), {
      durability: __privateGet(this, _options).durability
    }));
  }
  async close() {
    var _a;
    for (const fileId of __privateGet(this, _mapIdToFile).keys()) {
      await this.xClose(fileId);
    }
    await ((_a = __privateGet(this, _idb)) == null ? void 0 : _a.close());
    __privateSet(this, _idb, null);
  }
  /**
   * @param {string?} name 
   * @param {number} fileId 
   * @param {number} flags 
   * @param {DataView} pOutFlags 
   * @returns {number}
   */
  xOpen(name, fileId, flags, pOutFlags) {
    return this.handleAsync(async () => {
      if (name === null) name = `null_${fileId}`;
      log(`xOpen ${name} 0x${fileId.toString(16)} 0x${flags.toString(16)}`);
      try {
        const url = new URL(name, "http://localhost/");
        const file = {
          path: url.pathname,
          flags,
          block0: null,
          isMetadataChanged: true,
          locks: new WebLocksExclusive(url.pathname)
        };
        __privateGet(this, _mapIdToFile).set(fileId, file);
        await __privateGet(this, _idb).run("readwrite", async ({ blocks }) => {
          file.block0 = await blocks.get(__privateMethod(this, _IDBBatchAtomicVFS_instances, bound_fn).call(this, file, 0));
          if (!file.block0) {
            if (flags & SQLITE_OPEN_CREATE) {
              file.block0 = {
                path: file.path,
                offset: 0,
                version: 0,
                data: new Uint8Array(0),
                fileSize: 0
              };
              blocks.put(file.block0);
            } else {
              throw new Error(`file not found: ${file.path}`);
            }
          }
        });
        pOutFlags.setInt32(0, flags & SQLITE_OPEN_READONLY, true);
        return SQLITE_OK;
      } catch (e) {
        console.error(e);
        return SQLITE_CANTOPEN;
      }
    });
  }
  /**
   * @param {number} fileId 
   * @returns {number}
   */
  xClose(fileId) {
    return this.handleAsync(async () => {
      try {
        const file = __privateGet(this, _mapIdToFile).get(fileId);
        if (file) {
          log(`xClose ${file.path}`);
          __privateGet(this, _mapIdToFile).delete(fileId);
          if (file.flags & SQLITE_OPEN_DELETEONCLOSE) {
            __privateGet(this, _idb).run("readwrite", ({ blocks }) => {
              blocks.delete(IDBKeyRange.bound([file.path], [file.path, []]));
            });
          }
        }
        return SQLITE_OK;
      } catch (e) {
        console.error(e);
        return SQLITE_IOERR;
      }
    });
  }
  /**
   * @param {number} fileId 
   * @param {Uint8Array} pData 
   * @param {number} iOffset
   * @returns {number}
   */
  xRead(fileId, pData, iOffset) {
    return this.handleAsync(async () => {
      const file = __privateGet(this, _mapIdToFile).get(fileId);
      log(`xRead ${file.path} ${pData.byteLength} ${iOffset}`);
      try {
        const result = await __privateGet(this, _idb).run("readonly", async ({ blocks }) => {
          let pDataOffset = 0;
          while (pDataOffset < pData.byteLength) {
            const fileOffset = iOffset + pDataOffset;
            const block = fileOffset < file.block0.data.byteLength ? file.block0 : await blocks.get(__privateMethod(this, _IDBBatchAtomicVFS_instances, bound_fn).call(this, file, -fileOffset));
            if (!block || block.data.byteLength - block.offset <= fileOffset) {
              pData.fill(0, pDataOffset);
              return SQLITE_IOERR_SHORT_READ;
            }
            const buffer = pData.subarray(pDataOffset);
            const blockOffset = fileOffset + block.offset;
            const nBytesToCopy = Math.min(
              Math.max(block.data.byteLength - blockOffset, 0),
              // source bytes
              buffer.byteLength
            );
            buffer.set(block.data.subarray(blockOffset, blockOffset + nBytesToCopy));
            pDataOffset += nBytesToCopy;
          }
          return SQLITE_OK;
        });
        return result;
      } catch (e) {
        console.error(e);
        return SQLITE_IOERR;
      }
    });
  }
  /**
   * @param {number} fileId 
   * @param {Uint8Array} pData 
   * @param {number} iOffset
   * @returns {number}
   */
  xWrite(fileId, pData, iOffset) {
    const rewound = __privateGet(this, _pendingAsync).has(fileId);
    if (rewound || performance.now() - __privateGet(this, _taskTimestamp) > MAX_TASK_MILLIS) {
      const result = this.handleAsync(async () => {
        if (this.handleAsync !== super.handleAsync) {
          __privateGet(this, _pendingAsync).add(fileId);
        }
        await new Promise((resolve) => setTimeout(resolve));
        const result2 = __privateMethod(this, _IDBBatchAtomicVFS_instances, xWriteHelper_fn).call(this, fileId, pData, iOffset);
        __privateSet(this, _taskTimestamp, performance.now());
        return result2;
      });
      if (rewound) __privateGet(this, _pendingAsync).delete(fileId);
      return result;
    }
    return __privateMethod(this, _IDBBatchAtomicVFS_instances, xWriteHelper_fn).call(this, fileId, pData, iOffset);
  }
  /**
   * @param {number} fileId 
   * @param {number} iSize 
   * @returns {number}
   */
  xTruncate(fileId, iSize) {
    const file = __privateGet(this, _mapIdToFile).get(fileId);
    log(`xTruncate ${file.path} ${iSize}`);
    try {
      Object.assign(file.block0, {
        fileSize: iSize,
        data: file.block0.data.slice(0, iSize)
      });
      const block0 = Object.assign({}, file.block0);
      __privateGet(this, _idb).run("readwrite", ({ blocks }) => {
        blocks.delete(__privateMethod(this, _IDBBatchAtomicVFS_instances, bound_fn).call(this, file, -Infinity, -iSize));
        blocks.put(block0);
      });
      return SQLITE_OK;
    } catch (e) {
      console.error(e);
      return SQLITE_IOERR;
    }
  }
  /**
   * @param {number} fileId 
   * @param {number} flags 
   * @returns {number}
   */
  xSync(fileId, flags) {
    const rewound = __privateGet(this, _pendingAsync).has(fileId);
    if (rewound || __privateGet(this, _options).durability !== "relaxed" || performance.now() - __privateGet(this, _taskTimestamp) > MAX_TASK_MILLIS) {
      const result = this.handleAsync(async () => {
        if (this.handleAsync !== super.handleAsync) {
          __privateGet(this, _pendingAsync).add(fileId);
        }
        const result2 = await __privateMethod(this, _IDBBatchAtomicVFS_instances, xSyncHelper_fn).call(this, fileId, flags);
        __privateSet(this, _taskTimestamp, performance.now());
        return result2;
      });
      if (rewound) __privateGet(this, _pendingAsync).delete(fileId);
      return result;
    }
    const file = __privateGet(this, _mapIdToFile).get(fileId);
    log(`xSync ${file.path} ${flags}`);
    return SQLITE_OK;
  }
  /**
   * @param {number} fileId 
   * @param {DataView} pSize64 
   * @returns {number}
   */
  xFileSize(fileId, pSize64) {
    const file = __privateGet(this, _mapIdToFile).get(fileId);
    log(`xFileSize ${file.path}`);
    pSize64.setBigInt64(0, BigInt(file.block0.fileSize), true);
    return SQLITE_OK;
  }
  /**
   * @param {number} fileId 
   * @param {number} flags 
   * @returns {number}
   */
  xLock(fileId, flags) {
    return this.handleAsync(async () => {
      const file = __privateGet(this, _mapIdToFile).get(fileId);
      log(`xLock ${file.path} ${flags}`);
      try {
        const result = await file.locks.lock(flags);
        if (result === SQLITE_OK && file.locks.state === SQLITE_LOCK_SHARED) {
          file.block0 = await __privateGet(this, _idb).run("readonly", ({ blocks }) => {
            return blocks.get(__privateMethod(this, _IDBBatchAtomicVFS_instances, bound_fn).call(this, file, 0));
          });
        }
        return result;
      } catch (e) {
        console.error(e);
        return SQLITE_IOERR;
      }
    });
  }
  /**
   * @param {number} fileId 
   * @param {number} flags 
   * @returns {number}
   */
  xUnlock(fileId, flags) {
    return this.handleAsync(async () => {
      const file = __privateGet(this, _mapIdToFile).get(fileId);
      log(`xUnlock ${file.path} ${flags}`);
      try {
        return file.locks.unlock(flags);
      } catch (e) {
        console.error(e);
        return SQLITE_IOERR;
      }
    });
  }
  /**
   * @param {number} fileId 
   * @param {DataView} pResOut 
   * @returns {number}
   */
  xCheckReservedLock(fileId, pResOut) {
    return this.handleAsync(async () => {
      const file = __privateGet(this, _mapIdToFile).get(fileId);
      log(`xCheckReservedLock ${file.path}`);
      const isReserved = await file.locks.isSomewhereReserved();
      pResOut.setInt32(0, isReserved ? 1 : 0, true);
      return SQLITE_OK;
    });
  }
  /**
   * @param {number} fileId 
   * @returns {number}
   */
  xSectorSize(fileId) {
    log("xSectorSize");
    return SECTOR_SIZE;
  }
  /**
   * @param {number} fileId 
   * @returns {number}
   */
  xDeviceCharacteristics(fileId) {
    log("xDeviceCharacteristics");
    return SQLITE_IOCAP_BATCH_ATOMIC | SQLITE_IOCAP_SAFE_APPEND | SQLITE_IOCAP_SEQUENTIAL | SQLITE_IOCAP_UNDELETABLE_WHEN_OPEN;
  }
  /**
   * @param {number} fileId 
   * @param {number} op 
   * @param {DataView} pArg 
   * @returns {number}
   */
  xFileControl(fileId, op, pArg) {
    const file = __privateGet(this, _mapIdToFile).get(fileId);
    log(`xFileControl ${file.path} ${op}`);
    switch (op) {
      case 11:
        file.overwrite = true;
        return SQLITE_OK;
      case 21:
        if (file.overwrite) {
          try {
            return this.handleAsync(async () => {
              await __privateMethod(this, _IDBBatchAtomicVFS_instances, reblockIfNeeded_fn).call(this, file);
              return SQLITE_OK;
            });
          } catch (e) {
            console.error(e);
            return SQLITE_IOERR;
          }
        }
        if (file.isMetadataChanged) {
          try {
            __privateGet(this, _idb).run("readwrite", async ({ blocks }) => {
              await blocks.put(file.block0);
            });
            file.isMetadataChanged = false;
          } catch (e) {
            console.error(e);
            return SQLITE_IOERR;
          }
        }
        return SQLITE_OK;
      case 22:
        file.overwrite = false;
        return SQLITE_OK;
      case 31:
        return this.handleAsync(async () => {
          try {
            file.block0.version--;
            file.changedPages = /* @__PURE__ */ new Set();
            __privateGet(this, _idb).run("readwrite", async ({ blocks }) => {
              const keys = await blocks.index("version").getAllKeys(IDBKeyRange.bound(
                [file.path],
                [file.path, file.block0.version]
              ));
              for (const key of keys) {
                blocks.delete(key);
              }
            });
            return SQLITE_OK;
          } catch (e) {
            console.error(e);
            return SQLITE_IOERR;
          }
        });
      case 32:
        try {
          const block0 = Object.assign({}, file.block0);
          block0.data = block0.data.slice();
          const changedPages = file.changedPages;
          file.changedPages = null;
          file.isMetadataChanged = false;
          __privateGet(this, _idb).run("readwrite", async ({ blocks }) => {
            blocks.put(block0);
            const purgeBlock = await blocks.get([file.path, "purge", 0]) ?? {
              path: file.path,
              offset: "purge",
              version: 0,
              data: /* @__PURE__ */ new Map(),
              count: 0
            };
            purgeBlock.count += changedPages.size;
            for (const pageIndex of changedPages) {
              purgeBlock.data.set(pageIndex, block0.version);
            }
            blocks.put(purgeBlock);
            __privateMethod(this, _IDBBatchAtomicVFS_instances, maybePurge_fn).call(this, file.path, purgeBlock.count);
          });
          return SQLITE_OK;
        } catch (e) {
          console.error(e);
          return SQLITE_IOERR;
        }
      case 33:
        return this.handleAsync(async () => {
          try {
            file.changedPages = null;
            file.isMetadataChanged = false;
            file.block0 = await __privateGet(this, _idb).run("readonly", ({ blocks }) => {
              return blocks.get([file.path, 0, file.block0.version + 1]);
            });
            return SQLITE_OK;
          } catch (e) {
            console.error(e);
            return SQLITE_IOERR;
          }
        });
      default:
        return SQLITE_NOTFOUND;
    }
  }
  /**
   * @param {string} name 
   * @param {number} flags 
   * @param {DataView} pResOut 
   * @returns {number}
   */
  xAccess(name, flags, pResOut) {
    return this.handleAsync(async () => {
      try {
        const path = new URL(name, "file://localhost/").pathname;
        log(`xAccess ${path} ${flags}`);
        const key = await __privateGet(this, _idb).run("readonly", ({ blocks }) => {
          return blocks.getKey(__privateMethod(this, _IDBBatchAtomicVFS_instances, bound_fn).call(this, { path }, 0));
        });
        pResOut.setInt32(0, key ? 1 : 0, true);
        return SQLITE_OK;
      } catch (e) {
        console.error(e);
        return SQLITE_IOERR;
      }
    });
  }
  /**
   * @param {string} name 
   * @param {number} syncDir 
   * @returns {number}
   */
  xDelete(name, syncDir) {
    return this.handleAsync(async () => {
      const path = new URL(name, "file://localhost/").pathname;
      log(`xDelete ${path} ${syncDir}`);
      try {
        __privateGet(this, _idb).run("readwrite", ({ blocks }) => {
          return blocks.delete(IDBKeyRange.bound([path], [path, []]));
        });
        if (syncDir) {
          await __privateGet(this, _idb).sync();
        }
        return SQLITE_OK;
      } catch (e) {
        console.error(e);
        return SQLITE_IOERR;
      }
    });
  }
  /**
   * Purge obsolete blocks from a database file.
   * @param {string} path 
   */
  async purge(path) {
    const start = Date.now();
    await __privateGet(this, _idb).run("readwrite", async ({ blocks }) => {
      const purgeBlock = await blocks.get([path, "purge", 0]);
      if (purgeBlock) {
        for (const [pageOffset, version] of purgeBlock.data) {
          blocks.delete(IDBKeyRange.bound(
            [path, pageOffset, version],
            [path, pageOffset, Infinity],
            true,
            false
          ));
        }
        await blocks.delete([path, "purge", 0]);
      }
      log(`purge ${path} ${(purgeBlock == null ? void 0 : purgeBlock.data.size) ?? 0} pages in ${Date.now() - start} ms`);
    });
  }
};
_options = new WeakMap();
_mapIdToFile = new WeakMap();
_idb = new WeakMap();
_pendingPurges = new WeakMap();
_taskTimestamp = new WeakMap();
_pendingAsync = new WeakMap();
_IDBBatchAtomicVFS_instances = new WeakSet();
/**
 * @param {number} fileId 
 * @param {Uint8Array} pData 
 * @param {number} iOffset
 * @returns {number}
 */
xWriteHelper_fn = function(fileId, pData, iOffset) {
  const file = __privateGet(this, _mapIdToFile).get(fileId);
  log(`xWrite ${file.path} ${pData.byteLength} ${iOffset}`);
  try {
    const prevFileSize = file.block0.fileSize;
    if (file.block0.fileSize < iOffset + pData.byteLength) {
      file.block0.fileSize = iOffset + pData.byteLength;
      file.isMetadataChanged = true;
    }
    const block = iOffset === 0 ? file.block0 : {
      path: file.path,
      offset: -iOffset,
      version: file.block0.version,
      data: null
    };
    block.data = pData.slice();
    if (file.changedPages) {
      if (prevFileSize === file.block0.fileSize) {
        file.changedPages.add(-iOffset);
      }
      if (iOffset !== 0) {
        __privateGet(this, _idb).run("readwrite", ({ blocks }) => blocks.put(block));
      }
    } else {
      __privateGet(this, _idb).run("readwrite", ({ blocks }) => blocks.put(block));
    }
    file.isMetadataChanged = iOffset === 0 ? false : file.isMetadataChanged;
    return SQLITE_OK;
  } catch (e) {
    console.error(e);
    return SQLITE_IOERR;
  }
};
xSyncHelper_fn = async function(fileId, flags) {
  const file = __privateGet(this, _mapIdToFile).get(fileId);
  log(`xSync ${file.path} ${flags}`);
  try {
    if (file.isMetadataChanged) {
      __privateGet(this, _idb).run("readwrite", async ({ blocks }) => {
        await blocks.put(file.block0);
      });
      file.isMetadataChanged = false;
    }
    await __privateGet(this, _idb).sync();
  } catch (e) {
    console.error(e);
    return SQLITE_IOERR;
  }
  return SQLITE_OK;
};
/**
 * Conditionally schedule a purge task.
 * @param {string} path 
 * @param {number} nPages 
 */
maybePurge_fn = function(path, nPages) {
  if (__privateGet(this, _options).purge === "manual" || __privateGet(this, _pendingPurges).has(path) || nPages < __privateGet(this, _options).purgeAtLeast) {
    return;
  }
  if (globalThis.requestIdleCallback) {
    globalThis.requestIdleCallback(() => {
      this.purge(path);
      __privateGet(this, _pendingPurges).delete(path);
    });
  } else {
    setTimeout(() => {
      this.purge(path);
      __privateGet(this, _pendingPurges).delete(path);
    });
  }
  __privateGet(this, _pendingPurges).add(path);
};
bound_fn = function(file, begin, end = 0) {
  const version = !begin || -begin < file.block0.data.length ? -Infinity : file.block0.version;
  return IDBKeyRange.bound(
    [file.path, begin, version],
    [file.path, end, Infinity]
  );
};
reblockIfNeeded_fn = async function(file) {
  const oldPageSize = file.block0.data.length;
  if (oldPageSize < 18) return;
  const view = new DataView(file.block0.data.buffer, file.block0.data.byteOffset);
  let newPageSize = view.getUint16(16);
  if (newPageSize === 1) newPageSize = 65536;
  if (newPageSize === oldPageSize) return;
  const maxPageSize = Math.max(oldPageSize, newPageSize);
  const nOldPages = maxPageSize / oldPageSize;
  const nNewPages = maxPageSize / newPageSize;
  const newPageCount = view.getUint32(28);
  const fileSize = newPageCount * newPageSize;
  const version = file.block0.version;
  await __privateGet(this, _idb).run("readwrite", async ({ blocks }) => {
    const keys = await blocks.index("version").getAllKeys(IDBKeyRange.bound(
      [file.path, version + 1],
      [file.path, Infinity]
    ));
    for (const key of keys) {
      blocks.delete(key);
    }
    blocks.delete([file.path, "purge", 0]);
    for (let iOffset = 0; iOffset < fileSize; iOffset += maxPageSize) {
      const oldPages = await blocks.getAll(
        IDBKeyRange.lowerBound([file.path, -(iOffset + maxPageSize), Infinity]),
        nOldPages
      );
      for (const oldPage of oldPages) {
        blocks.delete([oldPage.path, oldPage.offset, oldPage.version]);
      }
      if (nNewPages === 1) {
        const buffer = new Uint8Array(newPageSize);
        for (const oldPage of oldPages) {
          buffer.set(oldPage.data, -(iOffset + oldPage.offset));
        }
        const newPage = {
          path: file.path,
          offset: -iOffset,
          version,
          data: buffer
        };
        if (newPage.offset === 0) {
          newPage.fileSize = fileSize;
          file.block0 = newPage;
        }
        blocks.put(newPage);
      } else {
        const oldPage = oldPages[0];
        for (let i = 0; i < nNewPages; ++i) {
          const offset = -(iOffset + i * newPageSize);
          if (-offset >= fileSize) break;
          const newPage = {
            path: oldPage.path,
            offset,
            version,
            data: oldPage.data.subarray(i * newPageSize, (i + 1) * newPageSize)
          };
          if (newPage.offset === 0) {
            newPage.fileSize = fileSize;
            file.block0 = newPage;
          }
          blocks.put(newPage);
        }
      }
    }
  });
};
function openDatabase(idbDatabaseName) {
  return new Promise((resolve, reject) => {
    const request = globalThis.indexedDB.open(idbDatabaseName, 5);
    request.addEventListener("upgradeneeded", function() {
      const blocks = request.result.createObjectStore("blocks", {
        keyPath: ["path", "offset", "version"]
      });
      blocks.createIndex("version", ["path", "version"]);
    });
    request.addEventListener("success", () => {
      resolve(request.result);
    });
    request.addEventListener("error", () => {
      reject(request.error);
    });
  });
}
export {
  IDBBatchAtomicVFS
};
//# sourceMappingURL=wa-sqlite_src_examples_IDBBatchAtomicVFS__js.js.map
